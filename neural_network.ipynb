{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1927857b",
   "metadata": {},
   "source": [
    "# CREATING AN NEURAL NETWORK FROM SCRATCH \n",
    "(**NO PYTORCH/TENSORFLOW** JUST PYTHON AND NUMPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58544f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return (x > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39bee230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        self.W = np.random.randn(n_inputs, n_outputs) * 0.01\n",
    "        self.b = np.zeros((1, n_outputs))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z = x @ self.W + self.b\n",
    "        return self.z  # activations applied outside\n",
    "    \n",
    "    def backward(self, dz, learning_rate):\n",
    "        # gradients\n",
    "        dW = self.x.T @ dz\n",
    "        db = np.sum(dz, axis=0, keepdims=True)\n",
    "        dx = dz @ self.W.T\n",
    "        \n",
    "        # update\n",
    "        self.W -= learning_rate * dW\n",
    "        self.b -= learning_rate * db\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432ab410",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activations):\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.zs = []\n",
    "        out = x\n",
    "        \n",
    "        for layer, act in zip(self.layers, self.activations):\n",
    "            z = layer.forward(out)\n",
    "            self.zs.append(z)\n",
    "            if act == \"sigmoid\":\n",
    "                out = sigmoid(z)\n",
    "            elif act == \"relu\":\n",
    "                out = relu(z)\n",
    "            elif act is None:\n",
    "                out = z\n",
    "        return out\n",
    "    \n",
    "    def backward(self, preds, y, lr):\n",
    "        # dL/d(preds) for MSE\n",
    "        dz = (preds - y)\n",
    "        \n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            act = self.activations[i]\n",
    "            z = self.zs[i]\n",
    "            \n",
    "            if act == \"sigmoid\":\n",
    "                dz *= sigmoid_deriv(z)\n",
    "            elif act == \"relu\":\n",
    "                dz *= relu_deriv(z)\n",
    "            \n",
    "            dz = self.layers[i].backward(dz, lr)\n",
    "    \n",
    "    def train(self, X, y, epochs, lr):\n",
    "        for epoch in range(epochs):\n",
    "            preds = self.forward(X)\n",
    "            loss = np.mean((preds - y)**2)\n",
    "            self.backward(preds, y, lr)\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss = {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb7f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 0.2500\n",
      "Epoch 1000, Loss = 0.1572\n",
      "Epoch 2000, Loss = 0.0073\n",
      "Epoch 3000, Loss = 0.0026\n",
      "Epoch 4000, Loss = 0.0015\n",
      "Epoch 5000, Loss = 0.0010\n",
      "Epoch 6000, Loss = 0.0008\n",
      "Epoch 7000, Loss = 0.0006\n",
      "Epoch 8000, Loss = 0.0005\n",
      "Epoch 9000, Loss = 0.0004\n",
      "Epoch 10000, Loss = 0.0004\n",
      "Epoch 11000, Loss = 0.0003\n",
      "Epoch 12000, Loss = 0.0003\n",
      "Epoch 13000, Loss = 0.0003\n",
      "Epoch 14000, Loss = 0.0002\n",
      "Epoch 15000, Loss = 0.0002\n",
      "Epoch 16000, Loss = 0.0002\n",
      "Epoch 17000, Loss = 0.0002\n",
      "Epoch 18000, Loss = 0.0002\n",
      "Epoch 19000, Loss = 0.0002\n",
      "Epoch 20000, Loss = 0.0002\n",
      "Epoch 21000, Loss = 0.0002\n",
      "Epoch 22000, Loss = 0.0001\n",
      "Epoch 23000, Loss = 0.0001\n",
      "Epoch 24000, Loss = 0.0001\n",
      "Epoch 25000, Loss = 0.0001\n",
      "Epoch 26000, Loss = 0.0001\n",
      "Epoch 27000, Loss = 0.0001\n",
      "Epoch 28000, Loss = 0.0001\n",
      "Epoch 29000, Loss = 0.0001\n",
      "Epoch 30000, Loss = 0.0001\n",
      "Epoch 31000, Loss = 0.0001\n",
      "Epoch 32000, Loss = 0.0001\n",
      "Epoch 33000, Loss = 0.0001\n",
      "Epoch 34000, Loss = 0.0001\n",
      "Epoch 35000, Loss = 0.0001\n",
      "Epoch 36000, Loss = 0.0001\n",
      "Epoch 37000, Loss = 0.0001\n",
      "Epoch 38000, Loss = 0.0001\n",
      "Epoch 39000, Loss = 0.0001\n",
      "Epoch 40000, Loss = 0.0001\n",
      "Epoch 41000, Loss = 0.0001\n",
      "Epoch 42000, Loss = 0.0001\n",
      "Epoch 43000, Loss = 0.0001\n",
      "Epoch 44000, Loss = 0.0001\n",
      "Epoch 45000, Loss = 0.0001\n",
      "Epoch 46000, Loss = 0.0001\n",
      "Epoch 47000, Loss = 0.0001\n",
      "Epoch 48000, Loss = 0.0001\n",
      "Epoch 49000, Loss = 0.0001\n",
      "Epoch 50000, Loss = 0.0001\n",
      "Epoch 51000, Loss = 0.0001\n",
      "Epoch 52000, Loss = 0.0001\n",
      "Epoch 53000, Loss = 0.0001\n",
      "Epoch 54000, Loss = 0.0001\n",
      "Epoch 55000, Loss = 0.0001\n",
      "Epoch 56000, Loss = 0.0000\n",
      "Epoch 57000, Loss = 0.0000\n",
      "Epoch 58000, Loss = 0.0000\n",
      "Epoch 59000, Loss = 0.0000\n",
      "Epoch 60000, Loss = 0.0000\n",
      "Epoch 61000, Loss = 0.0000\n",
      "Epoch 62000, Loss = 0.0000\n",
      "Epoch 63000, Loss = 0.0000\n",
      "Epoch 64000, Loss = 0.0000\n",
      "Epoch 65000, Loss = 0.0000\n",
      "Epoch 66000, Loss = 0.0000\n",
      "Epoch 67000, Loss = 0.0000\n",
      "Epoch 68000, Loss = 0.0000\n",
      "Epoch 69000, Loss = 0.0000\n",
      "Epoch 70000, Loss = 0.0000\n",
      "Epoch 71000, Loss = 0.0000\n",
      "Epoch 72000, Loss = 0.0000\n",
      "Epoch 73000, Loss = 0.0000\n",
      "Epoch 74000, Loss = 0.0000\n",
      "Epoch 75000, Loss = 0.0000\n",
      "Epoch 76000, Loss = 0.0000\n",
      "Epoch 77000, Loss = 0.0000\n",
      "Epoch 78000, Loss = 0.0000\n",
      "Epoch 79000, Loss = 0.0000\n",
      "Epoch 80000, Loss = 0.0000\n",
      "Epoch 81000, Loss = 0.0000\n",
      "Epoch 82000, Loss = 0.0000\n",
      "Epoch 83000, Loss = 0.0000\n",
      "Epoch 84000, Loss = 0.0000\n",
      "Epoch 85000, Loss = 0.0000\n",
      "Epoch 86000, Loss = 0.0000\n",
      "Epoch 87000, Loss = 0.0000\n",
      "Epoch 88000, Loss = 0.0000\n",
      "Epoch 89000, Loss = 0.0000\n",
      "Epoch 90000, Loss = 0.0000\n",
      "Epoch 91000, Loss = 0.0000\n",
      "Epoch 92000, Loss = 0.0000\n",
      "Epoch 93000, Loss = 0.0000\n",
      "Epoch 94000, Loss = 0.0000\n",
      "Epoch 95000, Loss = 0.0000\n",
      "Epoch 96000, Loss = 0.0000\n",
      "Epoch 97000, Loss = 0.0000\n",
      "Epoch 98000, Loss = 0.0000\n",
      "Epoch 99000, Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "X = np.array([\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Build network\n",
    "layers = [\n",
    "    DenseLayer(2, 4),\n",
    "    DenseLayer(4, 1)\n",
    "]\n",
    "\n",
    "activations = [\"relu\", \"sigmoid\"]\n",
    "\n",
    "nn = NeuralNetwork(layers, activations)\n",
    "nn.train(X, y, epochs=100000, lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fecef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[[0.00840225]\n",
      " [0.99643194]\n",
      " [0.99643194]\n",
      " [0.00299168]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\")\n",
    "print(nn.forward(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
